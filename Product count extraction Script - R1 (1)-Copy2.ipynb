{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc632444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.1.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.20.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\prasad.more\\appdata\\roaming\\python\\python39\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d2d74c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3d3f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\prasad.more\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\prasad.more\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f810394",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98bf8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.26.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3618aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Local Modules\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.keys import Keys ### Unused\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03357ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\learnings\\\\Jupyter Path'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing path of the working directory\n",
    "os.chdir(\"C:\\learnings\\Jupyter Path\")   # Replace your desired path in-place of mentioned path\n",
    "\n",
    "# Check current working directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "420a2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Excel into Pandas Dataframe\n",
    "read_excel = pd.read_excel(\"Test_Link_check.xlsx\", sheet_name = 0 ,header = None, index_col = None)\n",
    "df = pd.DataFrame(data = read_excel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "993b6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Defining the Function\"\"\"\n",
    "\n",
    "# Creating a Headless browser\n",
    "option = webdriver.ChromeOptions()\n",
    "option.headless = True\n",
    "\n",
    "def extract_product_count(url:str) -> list:\n",
    "    \"\"\"This function will extract product-counts from the websites mentioned in the Input Csv\n",
    "   \n",
    "    Argument: \n",
    "       url: str content\n",
    "       \n",
    "    Return:\n",
    "        response: list\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Instance of webdrive (Interface of browser that enables controls of browsers)\n",
    "    \n",
    "    driver = webdriver.Chrome(\"C:\\learnings\\Jupyter Path\\\\chromedriver.exe\", options= option)\n",
    "    \n",
    "    driver.get(url)   \n",
    "        \n",
    "    # Stabilize the webpage\n",
    "    time.sleep(6)    \n",
    "    page = driver.page_source\n",
    "        \n",
    "    # Exiting the webdriver\n",
    "    driver.quit() \n",
    "        \n",
    "    # Get the website's Static HTML DOM \n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "        \n",
    "    # Find the product count in the HTML DOM through X-path\n",
    "    get_text = soup.find('span', {'class':\"header-product-count\"})\n",
    "        \n",
    "    # Check if Product count available on website\n",
    "    \n",
    "    if get_text is None:\n",
    "        return [url, \"Count Not Available on Website\"]\n",
    "    \n",
    "    response = get_text.text\n",
    "        \n",
    "    # Remove parenthesis\n",
    "    trimed_response = re.sub(r'[()]',\"\",response) \n",
    "\n",
    "    # Convert the count into number and trim whitespaces\n",
    "    final_output = int(trimed_response.strip())\n",
    "\n",
    "    # Return urls and product count in list format\n",
    "    return [url, final_output]\n",
    "\n",
    "    ### Unnecessary else statement. Better to write it as the following:\n",
    "    \"\"\"\n",
    "    if get_text is None:\n",
    "        return [url, \"Count Not Available\"]\n",
    "    \n",
    "    response = get_text.text\n",
    "        \n",
    "    # Remove parenthesis\n",
    "    trimed_response = re.sub(r'[()]',\"\",response) \n",
    "\n",
    "    # Convert the count into number and trim whitespaces\n",
    "    final_output = int(trimed_response.strip())\n",
    "\n",
    "    # Return urls and product count in list format\n",
    "    return [url, final_output]\n",
    "    \"\"\"\n",
    "    ### As seen above, we take care of the exception case early on and then go on with the rest of the logic.\n",
    "    ### There's no need to use else because if the condition is met, the function will return and the rest will be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4eea9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prasad.more\\AppData\\Local\\Temp\\ipykernel_22424\\3709359442.py:20: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(\"C:\\learnings\\Jupyter Path\\\\chromedriver.exe\", options= option)\n"
     ]
    }
   ],
   "source": [
    "# Empty array to store data\n",
    "data = []\n",
    "\n",
    "for i in df.index:\n",
    "    \"\"\"Iteration through working Urls and storing product counts of each\"\"\"\n",
    "    \n",
    "    url = df[0][i]\n",
    "    response = requests.get(url)\n",
    "        \n",
    "    ### In some cases the status could be 201\n",
    "    # Check the status of response\n",
    "    if response.status_code == 200 or 201:     \n",
    "        product_count = extract_product_count(url)\n",
    "            \n",
    "        # Append output in list\n",
    "        data.append(product_count)\n",
    "            \n",
    "    else:\n",
    "        ### What about 50x? Needs better fault management. Maybe you can print the status code as well \n",
    "        ### For example: 'Could not extract product count. Page Status:' + response.status_code\n",
    "        # If status is 404 forbidden\n",
    "        print(\"Could not extract product count . Page Status: \" + response.status.code)\n",
    "        ### Absolutely unnecessary continue. The loop will continue without you telling it to\n",
    "        ### If you really want to use continue, then use it inside the if condition and remove the else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3ddf151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Check a excel file named \"Product_Count_2\" generated in your working directory'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Dataframe to structure data\n",
    "dataframe = pd.DataFrame(data = data, columns = [\"Urls\", \"Product Count\"])\n",
    "\n",
    "# Convert the output to excel\n",
    "dataframe.to_excel(\"Product_Count.xlsx\", sheet_name = \"Trail Run\" )\n",
    "\n",
    "\"\"\"Check a excel file named \"Product_Count_2\" generated in your working directory\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6d98b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 2e4df8a] comments removed\n",
      " 1 file changed, 2 insertions(+), 142 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in Product count extraction Script - R1 (1).ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "!git commit -a -m \"comments removed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cc6e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/prasadanilmore/product_count_extraction.git\n",
      "   e6a6e48..2e4df8a  main -> main\n"
     ]
    }
   ],
   "source": [
    "!git push origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f810d8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
